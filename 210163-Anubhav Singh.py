# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M7w-jQyEZg1bFZhcLy5sFtMcno1fLwDv
"""

import numpy as np
import pandas as pd
from tensorflow.keras.models import load_model
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
import math

def evaluate():
    # Input the csv file
    """
    Sample evaluation function
    Don't modify this function
    """
    df = pd.read_csv('sample_input.csv')

    actual_close = np.loadtxt('sample_close.txt')

    pred_close = predict_func(df)

    # Calculation of squared_error
    actual_close = np.array(actual_close)
    pred_close = np.array(pred_close)
    mean_square_error = np.mean(np.square(actual_close-pred_close))


    pred_prev = [df['Close'].iloc[-1]]
    pred_prev.append(pred_close[0])
    pred_curr = pred_close

    actual_prev = [df['Close'].iloc[-1]]
    actual_prev.append(actual_close[0])
    actual_curr = actual_close

    # Calculation of directional_accuracy
    pred_dir = np.array(pred_curr)-np.array(pred_prev)
    actual_dir = np.array(actual_curr)-np.array(actual_prev)
    dir_accuracy = np.mean((pred_dir*actual_dir)>0)*100

    print(f'Mean Square Error: {mean_square_error:.6f}\nDirectional Accuracy: {dir_accuracy:.1f}')

def create_dataset(dataset, time_step):
  dataX, dataY= [], []
  for i in range(len(dataset)-time_step):
    a=dataset[i:(i+time_step), 0]
    dataX.append(a)
    dataY.append(dataset[i+time_step,0])
  return np.array(dataX), np.array(dataY) #Function to group dataset into a group of 49 entries and using the 50th entry as y_test

def predict_func(data):
    data['Close'] = data['Close'].interpolate(method='linear') #Using Linear Interpolation

    scaler = MinMaxScaler(feature_range=(0, 1))
    df = scaler.fit_transform(np.array(data['Close']).reshape(-1, 1)) #Using MinMax Scaler to Scale down the data

    X_test, y_test = create_dataset(df, 49)

    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)
    y_test = y_test.reshape(y_test.shape[0], 1)

    model = load_model("model.h5") #Loading the trained model

    test_predict = model.predict(X_test) #Predicting the values

    test_predict = scaler.inverse_transform(test_predict) #Applying inverse transform to bring back the predicted values to required range

    y_test = scaler.inverse_transform(y_test) #Same with the initial data

    x_input = df[1:].reshape(1, -1)
    temp_input = list(x_input)
    temp_input = temp_input[0].tolist()

    lst_output = []
    n_steps = 49
    i = 0
    while (i < 2): #Iterating over while to predict 2 future values
        if (len(temp_input) > 49):
            x_input = np.array(temp_input[1:])
            x_input = x_input.reshape(1, -1)
            x_input = x_input.reshape(1, n_steps, 1)
            yhat = model.predict(x_input, verbose=0)
            temp_input.extend(yhat[0].tolist())
            temp_input = temp_input[1:]
            lst_output.extend(yhat.tolist())
            i = i + 1
        else:
            x_input = x_input.reshape(1, n_steps, 1)
            yhat = model.predict(x_input, verbose=0)
            temp_input.extend(yhat[0].tolist())
            lst_output.extend(yhat.tolist())
            i = i + 1

    day_new = np.arange(1, 50)
    day_pred = np.arange(50, 52)
    x = scaler.inverse_transform(lst_output)

    outList = []
    for nums in x:
        for val in nums:
            outList.append(val)   #Converting the 2D list to 1D list as required in the output
    return outList


if __name__== "__main__":
    evaluate()